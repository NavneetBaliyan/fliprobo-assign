{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words : ['affective', 'analysis', 'and', 'biometrics', 'computational', 'extract', 'identify', 'information', 'language', 'linguistics', 'natural', 'of', 'processing', 'quantify', 'refers', 'sentiment', 'states', 'study', 'subjective', 'systematically', 'text', 'the', 'to', 'use']\n"
     ]
    }
   ],
   "source": [
    "doc_1 = [\"Sentiment analysis refers to the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information\"]\n",
    "\n",
    "\n",
    "# This step will convert text into tokens \n",
    "vect1 = CountVectorizer()\n",
    "\n",
    "vect1.fit_transform(doc_1)\n",
    "\n",
    "bow_1=vect1.get_feature_names()\n",
    "print(\"bag of words :\",bow_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 15,\n",
       " 'analysis': 1,\n",
       " 'refers': 14,\n",
       " 'to': 22,\n",
       " 'the': 21,\n",
       " 'use': 23,\n",
       " 'of': 11,\n",
       " 'natural': 10,\n",
       " 'language': 8,\n",
       " 'processing': 12,\n",
       " 'text': 20,\n",
       " 'computational': 4,\n",
       " 'linguistics': 9,\n",
       " 'and': 2,\n",
       " 'biometrics': 3,\n",
       " 'systematically': 19,\n",
       " 'identify': 6,\n",
       " 'extract': 5,\n",
       " 'quantify': 13,\n",
       " 'study': 17,\n",
       " 'affective': 0,\n",
       " 'states': 16,\n",
       " 'subjective': 18,\n",
       " 'information': 7}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect1.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None,\n",
      "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
      "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
      "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
      "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
      "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
      "                            'itself', ...],\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "## Bag Of Words using stopwords (you can avoid writing extra steps to remove stopwords)\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "vect1 = CountVectorizer(stop_words=stop_words)\n",
    "print (vect1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_vect = CountVectorizer()\n",
    "c_vect.fit(doc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using function\n",
    "def text_matrix(document, countvect):\n",
    "    terms_doc = countvect.fit_transform(document)\n",
    "    return pd.DataFrame(terms_doc.toarray(),columns=countvect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>affective</th>\n",
       "      <th>analysis</th>\n",
       "      <th>and</th>\n",
       "      <th>biometrics</th>\n",
       "      <th>computational</th>\n",
       "      <th>extract</th>\n",
       "      <th>identify</th>\n",
       "      <th>information</th>\n",
       "      <th>language</th>\n",
       "      <th>linguistics</th>\n",
       "      <th>...</th>\n",
       "      <th>refers</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>states</th>\n",
       "      <th>study</th>\n",
       "      <th>subjective</th>\n",
       "      <th>systematically</th>\n",
       "      <th>text</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   affective  analysis  and  biometrics  computational  extract  identify  \\\n",
       "0          1         2    3           1              1        1         1   \n",
       "\n",
       "   information  language  linguistics  ...  refers  sentiment  states  study  \\\n",
       "0            1         1            1  ...       1          1       1      1   \n",
       "\n",
       "   subjective  systematically  text  the  to  use  \n",
       "0           1               1     1    1   2    1  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_matrix(doc_1, c_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Present at  [[0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 1 2 0 0]]\n",
      "original indexes ['affective', 'analysis', 'and', 'biometrics', 'computational', 'extract', 'identify', 'information', 'language', 'linguistics', 'natural', 'of', 'processing', 'quantify', 'refers', 'sentiment', 'states', 'study', 'subjective', 'systematically', 'text', 'the', 'to', 'use']\n"
     ]
    }
   ],
   "source": [
    "doc_2=[\"Sentiment Analysis is the most common text classification tool that analyses an incoming message and tells whether the underlying sentiment is positive, negative our neutral.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words : ['an', 'analyses', 'analysis', 'and', 'classification', 'common', 'incoming', 'is', 'message', 'most', 'negative', 'neutral', 'our', 'positive', 'sentiment', 'tells', 'text', 'that', 'the', 'tool', 'underlying', 'whether']\n",
      "vocab        : {'sentiment': 14, 'analysis': 2, 'is': 7, 'the': 18, 'most': 9, 'common': 5, 'text': 16, 'classification': 4, 'tool': 19, 'that': 17, 'analyses': 1, 'an': 0, 'incoming': 6, 'message': 8, 'and': 3, 'tells': 15, 'whether': 21, 'underlying': 20, 'positive': 13, 'negative': 10, 'our': 12, 'neutral': 11}\n"
     ]
    }
   ],
   "source": [
    "vect2 = CountVectorizer()\n",
    "vect2.fit_transform(doc_2)\n",
    "print(\"bag of words :\",vect2.get_feature_names())\n",
    "print(\"vocab        :\",vect2.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words : ['an', 'analyses', 'analysis', 'and', 'classification', 'common', 'incoming', 'is', 'message', 'most', 'negative', 'neutral', 'our', 'positive', 'sentiment', 'tells', 'text', 'that', 'the', 'tool', 'underlying', 'whether']\n"
     ]
    }
   ],
   "source": [
    "doc_2=[\"Sentiment Analysis is the most common text classification tool that analyses an incoming message and tells whether the underlying sentiment is positive, negative our neutral.\"]\n",
    "\n",
    "vect2 = CountVectorizer()\n",
    "vect2.fit_transform(doc_2)\n",
    "\n",
    "bow_2=vect2.get_feature_names()\n",
    "print(\"bag of words :\",bow_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None,\n",
      "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
      "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
      "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
      "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
      "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
      "                            'itself', ...],\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "vect2 = CountVectorizer(stop_words=stop_words)\n",
    "print (vect2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_new_vect = CountVectorizer()\n",
    "c_new_vect.fit(doc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>analyses</th>\n",
       "      <th>analysis</th>\n",
       "      <th>and</th>\n",
       "      <th>classification</th>\n",
       "      <th>common</th>\n",
       "      <th>incoming</th>\n",
       "      <th>is</th>\n",
       "      <th>message</th>\n",
       "      <th>most</th>\n",
       "      <th>...</th>\n",
       "      <th>our</th>\n",
       "      <th>positive</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tells</th>\n",
       "      <th>text</th>\n",
       "      <th>that</th>\n",
       "      <th>the</th>\n",
       "      <th>tool</th>\n",
       "      <th>underlying</th>\n",
       "      <th>whether</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   an  analyses  analysis  and  classification  common  incoming  is  message  \\\n",
       "0   1         1         1    1               1       1         1   2        1   \n",
       "\n",
       "   most  ...  our  positive  sentiment  tells  text  that  the  tool  \\\n",
       "0     1  ...    1         1          2      1     1     1    2     1   \n",
       "\n",
       "   underlying  whether  \n",
       "0           1        1  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_matrix(doc_2, c_new_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with the indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Present at  [[0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 1 2 0 0]]\n",
      "original indexes ['affective', 'analysis', 'and', 'biometrics', 'computational', 'extract', 'identify', 'information', 'language', 'linguistics', 'natural', 'of', 'processing', 'quantify', 'refers', 'sentiment', 'states', 'study', 'subjective', 'systematically', 'text', 'the', 'to', 'use']\n"
     ]
    }
   ],
   "source": [
    "c_new_vect = c_vect.transform(doc_2)\n",
    "\n",
    "print (\"Text Present at \",c_new_vect.toarray())\n",
    "\n",
    "# Compare with the indexes\n",
    "print (\"original indexes\",bow_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking how many words of bow_2 are presents in bow_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 5 words of bow_2 are presents in bow1\n",
      "['analysis', 'and', 'sentiment', 'text', 'the']\n"
     ]
    }
   ],
   "source": [
    "common_words=[]\n",
    "for i in bow_2:\n",
    "    for j in bow_1:\n",
    "        if i==j:\n",
    "            common_words.append(i)\n",
    "print(\"Total\",len(common_words), \"words of bow_2 are presents in bow1\")\n",
    "print(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
