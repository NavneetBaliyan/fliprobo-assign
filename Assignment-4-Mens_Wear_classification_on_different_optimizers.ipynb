{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,Dropout,Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set dir path where my images are saved\n",
    "datadir=\"C:/Users/Asus/MENS_WEAR/train\"\n",
    "categories=[\"Jeans\",\"Trouser\"]\n",
    "\n",
    "IMG_SIZE=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our training data for model training and also normalize the data for further processing.\n",
    "training_data=[]\n",
    "\n",
    "def create_training_data():\n",
    "    for category in categories:\n",
    "        path=os.path.join(datadir,category)\n",
    "        class_num=categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                \n",
    "                img_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "                new_array=cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
    "                training_data.append([new_array,class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "create_training_data()\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set dir path where my images are saved\n",
    "data_dir=\"C:/Users/Asus/MENS_WEAR/validation\"\n",
    "categories=[\"Jeans\",\"Trouser\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our training data for model training and also normalize the data for further processing.\n",
    "validation_data=[]\n",
    "\n",
    "def create_validation_data():\n",
    "    for category in categories:\n",
    "        path=os.path.join(data_dir,category)\n",
    "        class_num=categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                \n",
    "                img_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "                new_array=cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
    "                validation_data.append([new_array,class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "create_validation_data()\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from preventing the overfitting and underfitting we have to shuffle the data \n",
    "import random\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "y_train=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making x and y for training the model\n",
    "for features,label in training_data:\n",
    "    x_train.append(features)\n",
    "    y_train.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation=[]\n",
    "y_validation=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making x and y for training the model\n",
    "for features,label in validation_data:\n",
    "    x_validation.append(features)\n",
    "    y_validation.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.array(x_train)\n",
    "x_validation=np.array(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(x_train.shape[0],IMG_SIZE,IMG_SIZE,1)\n",
    "x_validation=x_validation.reshape(x_validation.shape[0],IMG_SIZE,IMG_SIZE,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.astype('float32')\n",
    "x_validation=x_validation.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train/255\n",
    "x_validation=x_validation/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class=2\n",
    "y_train=tf.keras.utils.to_categorical(y_train,num_class)\n",
    "y_validation=tf.keras.utils.to_categorical(y_validation,num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size=10\n",
    "epochs=15\n",
    "input_shape=(IMG_SIZE,IMG_SIZE,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 196, 196, 32)      832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 98, 98, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 94, 94, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 47, 47, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 141376)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                9048128   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 9,100,354\n",
      "Trainable params: 9,100,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#creating model\n",
    "model=Sequential()\n",
    "model.add(Conv2D(32,kernel_size=(5,5),strides=(1,1),\n",
    "                activation='relu',input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(64,kernel_size=(5,5),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(num_class,activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam,RMSprop,Nadam,SGD\n",
    "#from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.7038 - accuracy: 0.5865\n",
      "Epoch 00001: val_loss improved from inf to 0.60614, saving model to C:/Users/Asus/MENS_WEAR/mens_wear_adam_cnn.h5\n",
      "96/96 [==============================] - 62s 641ms/step - loss: 0.7038 - accuracy: 0.5865 - val_loss: 0.6061 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.5095 - accuracy: 0.7615\n",
      "Epoch 00002: val_loss improved from 0.60614 to 0.58394, saving model to C:/Users/Asus/MENS_WEAR/mens_wear_adam_cnn.h5\n",
      "96/96 [==============================] - 73s 764ms/step - loss: 0.5095 - accuracy: 0.7615 - val_loss: 0.5839 - val_accuracy: 0.7250 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.3249 - accuracy: 0.8656\n",
      "Epoch 00003: val_loss improved from 0.58394 to 0.57862, saving model to C:/Users/Asus/MENS_WEAR/mens_wear_adam_cnn.h5\n",
      "96/96 [==============================] - 81s 844ms/step - loss: 0.3249 - accuracy: 0.8656 - val_loss: 0.5786 - val_accuracy: 0.7750 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1860 - accuracy: 0.9312\n",
      "Epoch 00004: val_loss did not improve from 0.57862\n",
      "96/96 [==============================] - 85s 881ms/step - loss: 0.1860 - accuracy: 0.9312 - val_loss: 0.8259 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1096 - accuracy: 0.9625\n",
      "Epoch 00005: val_loss did not improve from 0.57862\n",
      "96/96 [==============================] - 103s 1s/step - loss: 0.1096 - accuracy: 0.9625 - val_loss: 0.9483 - val_accuracy: 0.7750 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 0.9635\n",
      "Epoch 00006: val_loss did not improve from 0.57862\n",
      "96/96 [==============================] - 104s 1s/step - loss: 0.1015 - accuracy: 0.9635 - val_loss: 0.8493 - val_accuracy: 0.8000 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.9812\n",
      "Epoch 00007: val_loss did not improve from 0.57862\n",
      "96/96 [==============================] - 118s 1s/step - loss: 0.0706 - accuracy: 0.9812 - val_loss: 1.3618 - val_accuracy: 0.7250 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9854Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.57862\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "96/96 [==============================] - 111s 1s/step - loss: 0.0473 - accuracy: 0.9854 - val_loss: 1.2964 - val_accuracy: 0.8250 - lr: 0.0010\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "def adam():\n",
    "    checkpoint=ModelCheckpoint('C:/Users/Asus/MENS_WEAR/mens_wear_adam_cnn.h5',monitor='val_loss',mode='min',save_best_only=True,\n",
    "                           verbose=1)\n",
    "\n",
    "    earlystop=EarlyStopping(monitor='val_loss',min_delta=0,patience=5,verbose=1,restore_best_weights=True)\n",
    "\n",
    "    reduce_lr=ReduceLROnPlateau(monitor='val_loss',factor=0.2,patience=5,verbose=1,min_delta=0.0001)\n",
    "\n",
    "    callbacks=[earlystop,checkpoint,reduce_lr]\n",
    "    \n",
    "    model.compile(loss=tf.keras.losses.binary_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "             metrics=['accuracy'])\n",
    "    history=model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,verbose=1,callbacks=callbacks,\n",
    "            validation_data=(x_validation,y_validation))\n",
    "adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.2141 - accuracy: 0.9083\n",
      "Epoch 00001: val_loss improved from inf to 0.91086, saving model to C:/Users/Asus/MENS_WEAR/mens_wear_RMSprop_cnn.h5\n",
      "96/96 [==============================] - 119s 1s/step - loss: 0.2141 - accuracy: 0.9083 - val_loss: 0.9109 - val_accuracy: 0.7750 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1325 - accuracy: 0.9479\n",
      "Epoch 00002: val_loss did not improve from 0.91086\n",
      "96/96 [==============================] - 117s 1s/step - loss: 0.1325 - accuracy: 0.9479 - val_loss: 1.1053 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9583\n",
      "Epoch 00003: val_loss did not improve from 0.91086\n",
      "96/96 [==============================] - 104s 1s/step - loss: 0.1200 - accuracy: 0.9583 - val_loss: 1.2866 - val_accuracy: 0.7750 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.9719\n",
      "Epoch 00004: val_loss did not improve from 0.91086\n",
      "96/96 [==============================] - 116s 1s/step - loss: 0.0698 - accuracy: 0.9719 - val_loss: 1.7394 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9823\n",
      "Epoch 00005: val_loss did not improve from 0.91086\n",
      "96/96 [==============================] - 118s 1s/step - loss: 0.0547 - accuracy: 0.9823 - val_loss: 2.0069 - val_accuracy: 0.7250 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9792Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.91086\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "96/96 [==============================] - 117s 1s/step - loss: 0.0617 - accuracy: 0.9792 - val_loss: 2.3747 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "def Rmsprop():\n",
    "    checkpoint=ModelCheckpoint('C:/Users/Asus/MENS_WEAR/mens_wear_RMSprop_cnn.h5',monitor='val_loss',mode='min',save_best_only=True,\n",
    "                           verbose=1)\n",
    "\n",
    "    earlystop=EarlyStopping(monitor='val_loss',min_delta=0,patience=5,verbose=1,restore_best_weights=True)\n",
    "\n",
    "    reduce_lr=ReduceLROnPlateau(monitor='val_loss',factor=0.2,patience=5,verbose=1,min_delta=0.0001)\n",
    "\n",
    "    callbacks=[earlystop,checkpoint,reduce_lr]\n",
    "    model.compile(loss=tf.keras.losses.binary_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.RMSprop(),\n",
    "             metrics=['accuracy'])\n",
    "    history=model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,verbose=1,callbacks=callbacks,\n",
    "            validation_data=(x_validation,y_validation))\n",
    "Rmsprop()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1419 - accuracy: 0.9438\n",
      "Epoch 00001: val_loss improved from inf to 1.07370, saving model to C:/Users/Asus/MENS_WEAR/mens_wear_Nadam_cnn.h5\n",
      "96/96 [==============================] - 114s 1s/step - loss: 0.1419 - accuracy: 0.9438 - val_loss: 1.0737 - val_accuracy: 0.8250 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.9688\n",
      "Epoch 00002: val_loss did not improve from 1.07370\n",
      "96/96 [==============================] - 122s 1s/step - loss: 0.0724 - accuracy: 0.9688 - val_loss: 1.3978 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.9792\n",
      "Epoch 00003: val_loss did not improve from 1.07370\n",
      "96/96 [==============================] - 113s 1s/step - loss: 0.0666 - accuracy: 0.9792 - val_loss: 1.2557 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.9677\n",
      "Epoch 00004: val_loss improved from 1.07370 to 0.80500, saving model to C:/Users/Asus/MENS_WEAR/mens_wear_Nadam_cnn.h5\n",
      "96/96 [==============================] - 125s 1s/step - loss: 0.1159 - accuracy: 0.9677 - val_loss: 0.8050 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0877 - accuracy: 0.9698\n",
      "Epoch 00005: val_loss did not improve from 0.80500\n",
      "96/96 [==============================] - 131s 1s/step - loss: 0.0877 - accuracy: 0.9698 - val_loss: 1.3726 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9896\n",
      "Epoch 00006: val_loss did not improve from 0.80500\n",
      "96/96 [==============================] - 144s 2s/step - loss: 0.0239 - accuracy: 0.9896 - val_loss: 1.4136 - val_accuracy: 0.7250 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9969\n",
      "Epoch 00007: val_loss did not improve from 0.80500\n",
      "96/96 [==============================] - 141s 1s/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 1.4677 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9990\n",
      "Epoch 00008: val_loss did not improve from 0.80500\n",
      "96/96 [==============================] - 135s 1s/step - loss: 0.0117 - accuracy: 0.9990 - val_loss: 1.5821 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 1.0000Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.80500\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "96/96 [==============================] - 145s 2s/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.7524 - val_accuracy: 0.7250 - lr: 0.0010\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "def Nadam():\n",
    "    checkpoint=ModelCheckpoint('C:/Users/Asus/MENS_WEAR/mens_wear_Nadam_cnn.h5',monitor='val_loss',mode='min',save_best_only=True,\n",
    "                           verbose=1)\n",
    "\n",
    "    earlystop=EarlyStopping(monitor='val_loss',min_delta=0,patience=5,verbose=1,restore_best_weights=True)\n",
    "\n",
    "    reduce_lr=ReduceLROnPlateau(monitor='val_loss',factor=0.2,patience=5,verbose=1,min_delta=0.0001)\n",
    "\n",
    "    callbacks=[earlystop,checkpoint,reduce_lr]\n",
    "    model.compile(loss=tf.keras.losses.binary_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Nadam(),\n",
    "             metrics=['accuracy'])\n",
    "    history=model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,verbose=1,callbacks=callbacks,\n",
    "            validation_data=(x_validation,y_validation))\n",
    "Nadam()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0902 - accuracy: 0.9698\n",
      "Epoch 00001: val_loss improved from inf to 1.00827, saving model to C:/Users/Asus/MENS_WEAR/mens_wear_SGD_momentum_cnn.h5\n",
      "96/96 [==============================] - 131s 1s/step - loss: 0.0902 - accuracy: 0.9698 - val_loss: 1.0083 - val_accuracy: 0.7750 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9917\n",
      "Epoch 00002: val_loss did not improve from 1.00827\n",
      "96/96 [==============================] - 107s 1s/step - loss: 0.0311 - accuracy: 0.9917 - val_loss: 1.0705 - val_accuracy: 0.8000 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9937\n",
      "Epoch 00003: val_loss did not improve from 1.00827\n",
      "96/96 [==============================] - 99s 1s/step - loss: 0.0249 - accuracy: 0.9937 - val_loss: 1.2161 - val_accuracy: 0.7750 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 0.9948\n",
      "Epoch 00004: val_loss did not improve from 1.00827\n",
      "96/96 [==============================] - 101s 1s/step - loss: 0.0192 - accuracy: 0.9948 - val_loss: 1.2164 - val_accuracy: 0.8000 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9958\n",
      "Epoch 00005: val_loss did not improve from 1.00827\n",
      "96/96 [==============================] - 100s 1s/step - loss: 0.0191 - accuracy: 0.9958 - val_loss: 1.2860 - val_accuracy: 0.8000 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9958Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.00827\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "96/96 [==============================] - 102s 1s/step - loss: 0.0157 - accuracy: 0.9958 - val_loss: 1.4799 - val_accuracy: 0.7750 - lr: 0.0010\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "def SGD_momentum():\n",
    "    checkpoint=ModelCheckpoint('C:/Users/Asus/MENS_WEAR/mens_wear_SGD_momentum_cnn.h5',monitor='val_loss',mode='min',save_best_only=True,\n",
    "                           verbose=1)\n",
    "\n",
    "    earlystop=EarlyStopping(monitor='val_loss',min_delta=0,patience=5,verbose=1,restore_best_weights=True)\n",
    "\n",
    "    reduce_lr=ReduceLROnPlateau(monitor='val_loss',factor=0.2,patience=5,verbose=1,min_delta=0.0001)\n",
    "\n",
    "    callbacks=[earlystop,checkpoint,reduce_lr]\n",
    "    model.compile(loss=tf.keras.losses.binary_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.SGD(lr=0.001,momentum=0.9),\n",
    "             metrics=['accuracy'])\n",
    "    history=model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,verbose=1,callbacks=callbacks,\n",
    "            validation_data=(x_validation,y_validation))\n",
    "SGD_momentum()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9875\n",
      "Epoch 00001: val_loss improved from inf to 1.05401, saving model to C:/Users/Asus/MENS_WEAR/mens_wear_NAG_cnn.h5\n",
      "96/96 [==============================] - 106s 1s/step - loss: 0.0340 - accuracy: 0.9875 - val_loss: 1.0540 - val_accuracy: 0.8000 - lr: 0.0100\n",
      "Epoch 2/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9948\n",
      "Epoch 00002: val_loss did not improve from 1.05401\n",
      "96/96 [==============================] - 103s 1s/step - loss: 0.0253 - accuracy: 0.9948 - val_loss: 1.1832 - val_accuracy: 0.8000 - lr: 0.0100\n",
      "Epoch 3/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9937\n",
      "Epoch 00003: val_loss did not improve from 1.05401\n",
      "96/96 [==============================] - 109s 1s/step - loss: 0.0211 - accuracy: 0.9937 - val_loss: 1.3684 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 4/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9948\n",
      "Epoch 00004: val_loss did not improve from 1.05401\n",
      "96/96 [==============================] - 110s 1s/step - loss: 0.0210 - accuracy: 0.9948 - val_loss: 1.2851 - val_accuracy: 0.7750 - lr: 0.0100\n",
      "Epoch 5/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9948\n",
      "Epoch 00005: val_loss did not improve from 1.05401\n",
      "96/96 [==============================] - 101s 1s/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 1.4328 - val_accuracy: 0.7750 - lr: 0.0100\n",
      "Epoch 6/15\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9958Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.05401\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "96/96 [==============================] - 81s 848ms/step - loss: 0.0152 - accuracy: 0.9958 - val_loss: 1.4586 - val_accuracy: 0.7750 - lr: 0.0100\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "def NAG():\n",
    "    checkpoint=ModelCheckpoint('C:/Users/Asus/MENS_WEAR/mens_wear_NAG_cnn.h5',monitor='val_loss',mode='min',save_best_only=True,\n",
    "                           verbose=1)\n",
    "\n",
    "    earlystop=EarlyStopping(monitor='val_loss',min_delta=0,patience=5,verbose=1,restore_best_weights=True)\n",
    "\n",
    "    reduce_lr=ReduceLROnPlateau(monitor='val_loss',factor=0.2,patience=5,verbose=1,min_delta=0.0001)\n",
    "\n",
    "    callbacks=[earlystop,checkpoint,reduce_lr]\n",
    "    model.compile(loss=tf.keras.losses.binary_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.SGD(lr=0.01,nesterov=0.9),\n",
    "             metrics=['accuracy'])\n",
    "    history=model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,verbose=1,callbacks=callbacks,\n",
    "            validation_data=(x_validation,y_validation))\n",
    "NAG()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the model\n",
    "\n",
    "import tensorflow as tf \n",
    "classifier = tf.keras.models.load_model('C:/Users/Asus/MENS_WEAR/mens_wear_NAG_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def draw_test(name,res,input_im):\n",
    "    BLACK=[0,0,0]\n",
    "    res=int(res)\n",
    "    if res==0:\n",
    "        pred=\"Jeans\"\n",
    "    if res==1:\n",
    "        pred=\"Trouser\"\n",
    "    expanded_image=cv2.copyMakeBorder(input_im,0,0,0,imageL.shape[0]*3, cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    expanded_image=cv2.cvtColor(expanded_image,cv2.COLOR_GRAY2BGR)\n",
    "    cv2.putText(expanded_image,str(pred),(100,100),cv2.FONT_HERSHEY_COMPLEX_SMALL,4,(1,60,0),5)\n",
    "    cv2.imshow(name,expanded_image)\n",
    "    \n",
    "    \n",
    "for i in range (0,10):\n",
    "    rand=np.random.randint(0,len(x_train))\n",
    "    input_im=x_train[rand]\n",
    "    \n",
    "    imageL=cv2.resize(input_im,None,fx=4,fy=4,interpolation=cv2.INTER_CUBIC)\n",
    "    input_im=input_im.reshape(1,200,200,1)\n",
    "    \n",
    "    #get prediction\n",
    "    res=str(classifier.predict_classes(input_im,1,verbose=0)[0])\n",
    "    \n",
    "    draw_test(\"Prediction\",res,imageL)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
